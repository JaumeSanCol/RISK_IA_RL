# ğŸ® SimulaciÃ³n de Risk: RL vs RL y RL vs HeurÃ­sticas

**Sistema completo para simular partidas de RISK con modelos entrenados y visualizarlas en la GUI.**

---

## ğŸ“ Â¿DÃ“NDE ESTOY? - GuÃ­a de NavegaciÃ³n

**Si estÃ¡s en el directorio `PPO/`:**

1. **Primero lee:** `PPO/README_RL_SIMULATION.md` â† DOCUMENTACIÃ“N PRINCIPAL
2. **Luego ejecuta:** `python validate_installation.py all`
3. **DespuÃ©s copia un comando de:** `PPO/QUICK_EXAMPLES.py`
4. **Para entender internals:** `PPO/ARCHITECTURE.py`
5. **Si tienes problemas:** `PPO/validate_installation.py troubleshoot`

---

## ğŸš€ Inicio RÃ¡pido (5 minutos)

### 1. Valida tu instalaciÃ³n

```bash
cd PPO
python validate_installation.py all
```

### 2. Ejecuta una partida de prueba

```bash
# RL vs RL
python play_rl_vs_rl.py logs_ppo/modelo1.zip logs_ppo/modelo2.zip -n 1 -w -v

# O RL vs HeurÃ­sticas
python play_rl_vs_heuristics.py logs_ppo/modelo.zip ../ai/random_ai.py -n 1 -w -v
```

### 3. Visualiza en la GUI

```bash
cd ..
python risk_game_viewer.py logs/RISKGAME_RLVRL_*.log
```

---

## ğŸ“š DocumentaciÃ³n

| Archivo | Para QuÃ© |
|---------|----------|
| `PPO/README_RL_SIMULATION.md` | **GuÃ­a completa del sistema** (START HERE) |
| `PPO/QUICK_EXAMPLES.py` | 10 comandos listos para copiar/pegar |
| `PPO/ARCHITECTURE.py` | Diagramas y flujos tÃ©cnicos |
| `PPO/validate_installation.py` | Validar instalaciÃ³n y troubleshooting |
| `PPO/INDEX.txt` | Overview de todos los archivos |

---

## ğŸ“‹ Archivos Nuevos Creados

### En `PPO/` directorio:

```
ppo_loader.py                    â† Cargador de modelos PPO
play_rl_vs_rl.py                â† Simulador: RL vs RL
play_rl_vs_heuristics.py        â† Simulador: RL vs HeurÃ­sticas
README_RL_SIMULATION.md          â† DocumentaciÃ³n PRINCIPAL
QUICK_EXAMPLES.py               â† Ejemplos de comandos
ARCHITECTURE.py                 â† DocumentaciÃ³n tÃ©cnica
validate_installation.py         â† Script de validaciÃ³n
INDEX.txt                        â† Index de archivos
```

---

## âœ¨ CaracterÃ­sticas

âœ… **Enfrentar modelos RL entre sÃ­**
- Soporta 2+ jugadores RL simultÃ¡neos
- EstadÃ­sticas automÃ¡ticas de victorias

âœ… **Enfrentar RL contra HeurÃ­sticas**
- DetecciÃ³n automÃ¡tica de tipo (`.zip` o `.py`)
- EstadÃ­sticas separadas por tipo de IA

âœ… **Logs compatibles con GUI**
- Formato idÃ©ntico a `play_risk_ai.py`
- VisualizaciÃ³n interactiva en `risk_game_viewer.py`

âœ… **Debugging fÃ¡cil**
- Modo verbose con detalles de cada turno
- Script de validaciÃ³n para solucionar problemas
- Manejo robusto de excepciones

---

## ğŸ¯ Casos de Uso

### Caso 1: Comparar dos modelos RL

```bash
cd PPO
python play_rl_vs_rl.py \
    logs_ppo/aggressive.zip \
    logs_ppo/defensive.zip \
    -n 10 -w
```

**Resultado:** 20 partidas (10 por modelo como jugador inicial), estadÃ­sticas finales.

---

### Caso 2: Probar RL contra HeurÃ­sticas

```bash
cd PPO
python play_rl_vs_heuristics.py \
    logs_ppo/modelo.zip \
    ../ai/attacker_ai.py \
    ../ai/random_ai.py \
    -n 5 -w
```

**Resultado:** 15 partidas, tabla de victorias por tipo de IA.

---

### Caso 3: Reproducir en GUI

```bash
# 1. Generar logs
cd PPO
python play_rl_vs_rl.py logs_ppo/m1.zip logs_ppo/m2.zip -n 1 -w

# 2. Abrir en GUI
cd ..
python risk_game_viewer.py logs/RISKGAME_RLVRL_*.log
```

**Resultado:** VisualizaciÃ³n paso a paso de la partida.

---

## âš™ï¸ Requisitos

### Instalados

```bash
pip install stable-baselines3[extra]
pip install sb3-contrib
pip install gymnasium
pip install numpy
```

### Estructura de directorios

```
RISK_IA_RL/
â”œâ”€â”€ PPO/                        â† EstÃ¡s aquÃ­
â”‚   â”œâ”€â”€ ppo_loader.py          âœ“ Nuevo
â”‚   â”œâ”€â”€ play_rl_vs_rl.py       âœ“ Nuevo
â”‚   â”œâ”€â”€ play_rl_vs_heuristics.py âœ“ Nuevo
â”‚   â”œâ”€â”€ README_RL_SIMULATION.md âœ“ Nuevo
â”‚   â”œâ”€â”€ logs_ppo/              â† Modelos .zip aquÃ­
â”‚   â””â”€â”€ risk_gym_env.py        âœ“ Debe existir
â”‚
â”œâ”€â”€ ai/                         â† IAs heurÃ­sticas (.py)
â”œâ”€â”€ logs/                       â† Logs generados aquÃ­
â”œâ”€â”€ risktools.py              â† Motor de Risk
â”œâ”€â”€ world.zip                 â† Tablero
â””â”€â”€ risk_game_viewer.py       â† GUI
```

---

## ğŸ”§ Troubleshooting RÃ¡pido

| Problema | SoluciÃ³n |
|----------|----------|
| `ModuleNotFoundError: risktools` | Ejecuta desde `PPO/` |
| `FileNotFoundError: modelo no encontrado` | Verifica `ls logs_ppo/` |
| `ImportError: risk_gym_env` | Verifica que estÃ¡ en `PPO/` |
| `world.zip not found` | Debe estar en directorio raÃ­z |
| Las IAs juegan invÃ¡lido constantemente | Usa `-v` para debug, reentrana el modelo |

**MÃ¡s detalles:** `python validate_installation.py troubleshoot`

---

## ğŸ“Š Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Entrenar (train_ppo.py)                              â”‚
â”‚    â†’ logs_ppo/*.zip                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Simular (play_rl_vs_*.py)                            â”‚
â”‚    â†’ logs/RISKGAME_*.log                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Visualizar (risk_game_viewer.py)                     â”‚
â”‚    â†’ ReproducciÃ³n interactiva en GUI                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– PrÃ³ximos Pasos

1. **Lee la documentaciÃ³n principal:**
   ```bash
   cd PPO
   cat README_RL_SIMULATION.md  # o abre en tu editor
   ```

2. **Valida tu sistema:**
   ```bash
   python validate_installation.py all
   ```

3. **Ejecuta tu primer ejemplo:**
   ```bash
   cat QUICK_EXAMPLES.py  # Copia un comando
   python play_rl_vs_rl.py [modelos] -n 1 -w -v
   ```

4. **Visualiza en GUI:**
   ```bash
   cd ..
   python risk_game_viewer.py logs/RISKGAME_*.log
   ```

---

## ğŸ¤” Preguntas Frecuentes

**P: Â¿QuÃ© modelos necesito?**
R: Modelos `.zip` entrenados con `train_ppo.py` en `PPO/logs_ppo/`

**P: Â¿Puedo enfrentar diferentes tipos de IAs?**
R: SÃ­, `play_rl_vs_heuristics.py` soporta mezcla libre de `.zip` (RL) y `.py` (heurÃ­stica)

**P: Â¿Los logs son compatibles con la GUI?**
R: Completamente. Formato idÃ©ntico a `play_risk_ai.py`

**P: Â¿Puedo entrenar mientras simulo?**
R: SÃ­, usa diferentes procesos/terminales

**P: Â¿CÃ³mo mido el rendimiento?**
R: Las estadÃ­sticas finales muestran victorias, empates, timeouts y turnos promedio

**MÃ¡s en:** `PPO/README_RL_SIMULATION.md` â†’ FAQ

---

## ğŸ“ Soporte

- **DocumentaciÃ³n:** `PPO/README_RL_SIMULATION.md`
- **Ejemplos:** `PPO/QUICK_EXAMPLES.py`
- **Troubleshooting:** `python PPO/validate_installation.py troubleshoot`
- **TÃ©cnico:** `PPO/ARCHITECTURE.py`

---

## ğŸ“ Notas

- **Compatibilidad:** 100% compatible con `risk_game_viewer.py` y `play_risk_ai.py`
- **No hay cambios:** CÃ³digo existente sin modificaciones
- **Modular:** Puedes importar `PPOPlayer` en tus propios scripts
- **Robusto:** Manejo de excepciones y fallback a acciones aleatorias

---

**Â¡Listo para usar!** Comienza por: `cd PPO && python validate_installation.py all`
