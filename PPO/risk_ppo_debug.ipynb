{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a685ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio padre añadido al path: c:\\Users\\murci\\Documents\\Master_IA\\Reinforcement_Learning\\RISK-AI\n",
      "✅ Librerías de RISK importadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# --- CONFIGURACIÓN DE PATH ---\n",
    "# Asumimos que el notebook está en RISK-AI/PPO/\n",
    "# Añadimos el directorio padre (RISK-AI/) al path para importar risktools\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "print(f\"Directorio padre añadido al path: {parent_dir}\")\n",
    "\n",
    "# --- IMPORTS DEL JUEGO ---\n",
    "try:\n",
    "    import risktools\n",
    "    from clases.state import RiskState\n",
    "    from config_atrib import *\n",
    "    \n",
    "    print(\"✅ Librerías de RISK importadas correctamente.\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importando risktools: {e}\")\n",
    "    print(\"Verifica que estás ejecutando el notebook desde la carpeta RISK-AI/PPO/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e05a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskTotalControlEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Entorno Gymnasium para jugar a RISK con control total.\n",
    "    CORREGIDO: Inicialización manual del tablero para evitar dependencias de la GUI.\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human']}\n",
    "\n",
    "    def __init__(self, enemy_ai_class=None):\n",
    "        super(RiskTotalControlEnv, self).__init__()\n",
    "        \n",
    "        # Cargar el tablero UNA sola vez al inicio\n",
    "        world_path = os.path.join(parent_dir, \"world.zip\")\n",
    "        self.board_base = risktools.loadBoard(world_path)\n",
    "        self.n_territories = len(self.board_base.territories)\n",
    "        \n",
    "        # Configurar valores de cartas por defecto (ya que loadBoard no los trae)\n",
    "        self.board_base.set_turn_in_values([4, 6, 8, 10, 12, 15])\n",
    "        self.board_base.set_increment_value(5)\n",
    "        \n",
    "        # ACCIONES: MultiDiscrete([Tipo(7), Origen(42), Destino(42), Cantidad(10)])\n",
    "        self.action_space = spaces.MultiDiscrete([7, 42, 42, 10])\n",
    "        \n",
    "        # OBSERVACIÓN\n",
    "        self.obs_dim = (self.n_territories * 3) + 20 \n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.obs_dim,), dtype=np.float32)\n",
    "\n",
    "        self.state = None\n",
    "        self.player_idx = 0\n",
    "        self.enemy_ai = enemy_ai_class\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        # 1. Crear Jugadores\n",
    "        # Usamos las constantes importadas de config_atrib\n",
    "        p1 = risktools.RiskPlayer(\"Agent_PPO\", 0, 0, False, ECON_START, HAPP_START, DEVP_START)\n",
    "        p2 = risktools.RiskPlayer(\"Enemy_Bot\", 1, 0, False, ECON_START, HAPP_START, DEVP_START)\n",
    "        \n",
    "        # Parche de compatibilidad (atributos legacy camelCase)\n",
    "        p1.freeArmies = p1.free_armies\n",
    "        p1.conqueredTerritory = p1.conquered_territory\n",
    "        p2.freeArmies = p2.free_armies\n",
    "        p2.conqueredTerritory = p2.conquered_territory\n",
    "\n",
    "        # 2. Configurar el Tablero (Usando el cargado, sin createRiskBoard)\n",
    "        # Reutilizamos la estructura del mapa pero limpiamos los jugadores\n",
    "        self.board = self.board_base # Referencia al objeto base\n",
    "        self.board.players = []      # Limpiar lista jugadores\n",
    "        self.board.player_to_id = {} # Limpiar diccionarios\n",
    "        self.board.id_to_player = {}\n",
    "        \n",
    "        # Añadir nuestros jugadores al tablero\n",
    "        self.board.add_player(p1)\n",
    "        self.board.add_player(p2)\n",
    "\n",
    "        # 3. Configurar engine global (por seguridad, aunque intentamos no usarlo)\n",
    "        risktools.riskengine.playerorder = [p1, p2]\n",
    "        risktools.riskengine.currentplayer = p1\n",
    "        risktools.riskengine.phase = 'Preposition'\n",
    "        \n",
    "        # 4. Crear Estado Inicial\n",
    "        # getInitialState usa self.board.players, que acabamos de configurar\n",
    "        self.state = risktools.getInitialState(self.board)\n",
    "        \n",
    "        # 5. Setup Rápido (Saltar fase de asignación manual)\n",
    "        self._fast_random_setup()\n",
    "        \n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        act_type, act_src, act_dst, act_amt = action\n",
    "        \n",
    "        # Decodificar acción\n",
    "        game_action = self._decode_action(act_type, act_src, act_dst, act_amt)\n",
    "        \n",
    "        reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {\"valid\": game_action is not None}\n",
    "        \n",
    "        if game_action is None:\n",
    "            return self._get_obs(), -1.0, False, False, info\n",
    "\n",
    "        # Ejecutar acción en el motor\n",
    "        try:\n",
    "            next_states, probs = risktools.simulateAction(self.state, game_action)\n",
    "            if len(next_states) > 1:\n",
    "                idx = np.random.choice(len(next_states), p=probs)\n",
    "                self.state = next_states[idx]\n",
    "            else:\n",
    "                self.state = next_states[0]\n",
    "        except Exception as e:\n",
    "            # Si hay error interno, penalizamos y terminamos episodio (evita crash)\n",
    "            return self._get_obs(), -10, True, False, {\"error\": str(e), \"valid\": True}\n",
    "\n",
    "        # Recompensa\n",
    "        reward += self._calculate_reward()\n",
    "        \n",
    "        # Verificar Fin de Juego\n",
    "        if self.state.turn_type == 'GameOver':\n",
    "            terminated = True\n",
    "            winners = [i for i, p in enumerate(self.state.players) if not p.game_over]\n",
    "            # Si ganamos (somos player 0 y estamos en la lista de ganadores)\n",
    "            if self.player_idx in winners and len(winners) == 1:\n",
    "                reward += 100\n",
    "            else:\n",
    "                reward -= 100\n",
    "        \n",
    "        # Turno del enemigo\n",
    "        elif self.state.current_player != self.player_idx:\n",
    "            self._simulate_enemy_turn()\n",
    "            if self.state.players[self.player_idx].game_over:\n",
    "                terminated = True\n",
    "                reward -= 100\n",
    "            elif self.state.turn_type == 'GameOver':\n",
    "                 # Caso raro donde el enemigo muere solo o empata\n",
    "                 terminated = True\n",
    "\n",
    "        return self._get_obs(), reward, terminated, truncated, info\n",
    "\n",
    "    def action_masks(self):\n",
    "        \"\"\"Mascara de acciones válidas\"\"\"\n",
    "        allowed_dict = risktools.getAllowedFaseActions(self.state)\n",
    "        \n",
    "        mask_type = [False] * 7\n",
    "        type_map = {\n",
    "            'Pasar': 0, 'Comprar_Soldados': 1, 'Place': 2, \n",
    "            'Attack': 3, 'Occupy': 4, 'Fortify': 5, 'Invertir': 6,\n",
    "            'PrePlace': 2\n",
    "        }\n",
    "        \n",
    "        valid_objects = []\n",
    "        for key, actions in allowed_dict.items():\n",
    "            if key in type_map and len(actions) > 0:\n",
    "                mask_type[type_map[key]] = True\n",
    "                valid_objects.extend(actions)\n",
    "                \n",
    "        if not any(mask_type): mask_type[0] = True\n",
    "\n",
    "        mask_src = [False] * 42\n",
    "        mask_dst = [False] * 42\n",
    "        \n",
    "        for act in valid_objects:\n",
    "            if hasattr(act, 'from_territory') and act.from_territory:\n",
    "                if act.from_territory in self.board.territory_to_id:\n",
    "                    mask_src[self.board.territory_to_id[act.from_territory]] = True\n",
    "            else:\n",
    "                mask_src[0] = True \n",
    "                \n",
    "            if hasattr(act, 'to_territory') and act.to_territory:\n",
    "                 if act.to_territory in self.board.territory_to_id:\n",
    "                    mask_dst[self.board.territory_to_id[act.to_territory]] = True\n",
    "            else:\n",
    "                mask_dst[0] = True \n",
    "\n",
    "        mask_amt = [True] * 10\n",
    "        return np.concatenate([mask_type, mask_src, mask_dst, mask_amt])\n",
    "\n",
    "    def _decode_action(self, type_idx, src_id, dst_id, amt_idx):\n",
    "        allowed_dict = risktools.getAllowedFaseActions(self.state)\n",
    "        target_type = None\n",
    "        \n",
    "        map_idx_str = {0:'Pasar', 1:'Comprar_Soldados', 2:'Place', 3:'Attack', 4:'Occupy', 5:'Fortify', 6:'Invertir'}\n",
    "        target_type = map_idx_str.get(type_idx)\n",
    "        \n",
    "        if target_type == 'Place' and 'PrePlace' in allowed_dict: target_type = 'PrePlace'\n",
    "            \n",
    "        if target_type not in allowed_dict: return None\n",
    "            \n",
    "        candidates = allowed_dict[target_type]\n",
    "        \n",
    "        # Obtener nombres de territorios (si IDs son válidos)\n",
    "        src_name = self.board.territories[src_id].name if src_id < self.n_territories else None\n",
    "        dst_name = self.board.territories[dst_id].name if dst_id < self.n_territories else None\n",
    "        \n",
    "        best_match = None\n",
    "        for act in candidates:\n",
    "            match_src = True\n",
    "            match_dst = True\n",
    "            \n",
    "            if hasattr(act, 'from_territory') and act.from_territory:\n",
    "                if act.from_territory != src_name: match_src = False\n",
    "            if hasattr(act, 'to_territory') and act.to_territory:\n",
    "                if act.to_territory != dst_name: match_dst = False\n",
    "                    \n",
    "            if match_src and match_dst:\n",
    "                best_match = act\n",
    "                break\n",
    "        \n",
    "        if best_match:\n",
    "            # Si es accion de comprar o mover tropas, inyectamos la cantidad\n",
    "            if hasattr(best_match, 'armies'):\n",
    "                 # amt_idx (0-9) -> cantidad. Simplificación: 1 unidad + índice\n",
    "                 # En un caso real leeríamos límites del estado.\n",
    "                 best_match.armies = max(1, amt_idx) \n",
    "            # Para comprar soldados\n",
    "            if hasattr(best_match, 'amount'): # Si la clase usa 'amount'\n",
    "                 best_match.amount = max(1, amt_idx)\n",
    "\n",
    "        return best_match\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = []\n",
    "        for i in range(self.n_territories):\n",
    "            owner = self.state.owners[i]\n",
    "            armies = self.state.armies[i]\n",
    "            obs.append(1.0 if owner == self.player_idx else 0.0)\n",
    "            obs.append(1.0 if owner is not None and owner != self.player_idx else 0.0)\n",
    "            obs.append(min(armies / 100.0, 1.0))\n",
    "            \n",
    "        me = self.state.players[self.player_idx]\n",
    "        enemy = self.state.players[1 if self.player_idx == 0 else 0]\n",
    "        \n",
    "        obs.extend([\n",
    "            min(me.economy / 200.0, 1.0),\n",
    "            min(me.free_armies / 50.0, 1.0),\n",
    "            min(enemy.economy / 200.0, 1.0),\n",
    "            min(sum(self.state.armies) / 500.0, 1.0)\n",
    "        ])\n",
    "        \n",
    "        phase_map = {'fase_0':0, 'fase_1':1, 'fase_2':2, 'fase_3':3}\n",
    "        phase_vec = [0.0]*4\n",
    "        phase_vec[phase_map.get(self.state.fase, 0)] = 1.0\n",
    "        obs.extend(phase_vec)\n",
    "        \n",
    "        current_len = len(obs)\n",
    "        if current_len < self.obs_dim:\n",
    "            obs.extend([0.0] * (self.obs_dim - current_len))\n",
    "            \n",
    "        return np.array(obs[:self.obs_dim], dtype=np.float32)\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        territories = sum(1 for o in self.state.owners if o == self.player_idx)\n",
    "        return territories * 0.01\n",
    "\n",
    "    def _simulate_enemy_turn(self):\n",
    "        steps = 0\n",
    "        while self.state.current_player != self.player_idx and self.state.turn_type != 'GameOver' and steps < 50:\n",
    "            actions_dict = risktools.getAllowedFaseActions(self.state)\n",
    "            all_actions = list(itertools.chain.from_iterable(actions_dict.values()))\n",
    "            if not all_actions: break\n",
    "            \n",
    "            # Elegir aleatorio\n",
    "            action = random.choice(all_actions)\n",
    "            \n",
    "            # Ejecutar\n",
    "            next_states, probs = risktools.simulateAction(self.state, action)\n",
    "            if len(next_states) > 1:\n",
    "                idx = np.random.choice(len(next_states), p=probs)\n",
    "                self.state = next_states[idx]\n",
    "            else:\n",
    "                self.state = next_states[0]\n",
    "            steps += 1\n",
    "\n",
    "    def _fast_random_setup(self):\n",
    "        ids = list(range(self.n_territories))\n",
    "        random.shuffle(ids)\n",
    "        for i, tid in enumerate(ids):\n",
    "            owner = i % 2\n",
    "            self.state.owners[tid] = owner\n",
    "            self.state.armies[tid] = 3\n",
    "        self.state.fase = 'fase_1'\n",
    "        self.state.turn_type = 'Comprar_Soldados'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7340823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado inicial shape: (146,)\n",
      "Probando bucle de juego aleatorio...\n",
      "Step 0: Reward=0.21, Valid=True\n",
      "Step 1: Reward=-1.0, Valid=False\n",
      "Step 2: Reward=-1.0, Valid=False\n",
      "Step 3: Reward=-1.0, Valid=False\n",
      "Step 4: Reward=-1.0, Valid=False\n",
      "Step 5: Reward=-1.0, Valid=False\n",
      "Step 6: Reward=0.21, Valid=True\n",
      "Step 7: Reward=-1.0, Valid=False\n",
      "Step 8: Reward=-1.0, Valid=False\n",
      "Step 9: Reward=-1.0, Valid=False\n",
      "Step 10: Reward=-1.0, Valid=False\n",
      "Step 11: Reward=-1.0, Valid=False\n",
      "Step 12: Reward=-1.0, Valid=False\n",
      "Step 13: Reward=-1.0, Valid=False\n",
      "Step 14: Reward=-1.0, Valid=False\n",
      "Step 15: Reward=-1.0, Valid=False\n",
      "Step 16: Reward=-1.0, Valid=False\n",
      "Step 17: Reward=-1.0, Valid=False\n",
      "Step 18: Reward=0.21, Valid=True\n",
      "Step 19: Reward=-1.0, Valid=False\n",
      "✅ Test finalizado sin crashes críticos.\n"
     ]
    }
   ],
   "source": [
    "# --- SMOKE TEST ---\n",
    "env = RiskTotalControlEnv()\n",
    "obs, _ = env.reset()\n",
    "print(\"Estado inicial shape:\", obs.shape)\n",
    "\n",
    "done = False\n",
    "steps = 0\n",
    "\n",
    "print(\"Probando bucle de juego aleatorio...\")\n",
    "while not done and steps < 20:\n",
    "    # 1. Usamos la máscara para elegir una acción válida al azar\n",
    "    masks = env.action_masks()\n",
    "    # masks es un array concatenado [7, 42, 42, 10]\n",
    "    # Para testear, simplemente probamos step con valores dummy hasta acertar (fuerza bruta)\n",
    "    # O mejor, usamos ActionMasker de SB3 si está instalado, pero aquí lo hacemos manual:\n",
    "    \n",
    "    # Simplemente pedimos una acción válida aleatoria del motor para probar el step\n",
    "    # Esto es trampa pero sirve para ver si el step crashea\n",
    "    allowed = risktools.getAllowedFaseActions(env.state)\n",
    "    \n",
    "    # Intentamos generar una acción dummy que coincida con una válida\n",
    "    # Para simplificar el test manual, usaremos una acción \"Pasar\" que casi siempre es válida o un ataque\n",
    "    # Si falla, el entorno devuelve recompensa negativa, que es lo esperado.\n",
    "    \n",
    "    action = env.action_space.sample() # Acción aleatoria\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    print(f\"Step {steps}: Reward={reward}, Valid={info['valid']}\")\n",
    "    \n",
    "    if terminated:\n",
    "        print(\"Juego terminado.\")\n",
    "        done = True\n",
    "    steps += 1\n",
    "\n",
    "print(\"✅ Test finalizado sin crashes críticos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
